{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nlp_operations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQspFr/q2mKmqnVJ7YtEj9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geekanshul/AIWorkshopMaterial/blob/master/Nlp_operations_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVOuyh-ljMji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk # to use nlp\n",
        "#nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtrepkO4jWis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# after downloading all data \n",
        "from urllib  import request   #  for downloading  data from url \n",
        "from  bs4  import  BeautifulSoup  #  for souping\n",
        "import  time \n",
        "import  re  #  importing  regular expression \n",
        "#  pointing to URL \n",
        "url='https://en.wikipedia.org/wiki/Machine_learning'\n",
        "#url='https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic'\n",
        "#url='https://www.php.net/'\n",
        "\n",
        "htmldata=request.urlopen(url)\n",
        "#htmldata.read()  # it will download data in html format \n",
        "soupdata=BeautifulSoup(htmldata,'html5lib')\n",
        "#      html data ,  html parser --      \n",
        "#  what is  HTML parser -- is collection of html tags that can scrape data from particular tag like h1 , html , a , p\n",
        "#  now selecting a particular tag for data scrape \n",
        "atagdata=soupdata.findAll('p')\n",
        "#  now converting  data into string  format  from HTML format \n",
        "\n",
        "mydata=\"\"\n",
        "for i in atagdata:\n",
        "  mydata +=  i.text \n",
        "\n",
        "web_data = mydata\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovj81FeukAvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import sentencee tokenization\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tM7MLWdlnn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passing the data to sentence tokenization\n",
        "sentences = sent_tokenize(web_data)\n",
        "# import time\n",
        "# # printing all sentences one by one\n",
        "\n",
        "# for s in sentences:\n",
        "#   print(s)\n",
        "#   time.sleep(1)\n",
        "\n",
        "print(sentences) # it will convert into sentences with comma seprated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f_JdMGkmP8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}